{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11k3LZm4y6cK",
        "outputId": "1449b835-1df2-46cd-8c7d-78b0c04910d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from memory_profiler import memory_usage\n",
        "import bisect"
      ],
      "metadata": {
        "id": "FU845OdfeByt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PiecewiseLinearIndex:\n",
        "    def __init__(self, num_segments=10):\n",
        "        self.num_segments = num_segments\n",
        "        self.models = []\n",
        "        self.segment_boundaries = []\n",
        "\n",
        "    def train(self, data):\n",
        "        segment_size = len(data) // self.num_segments\n",
        "        for i in range(self.num_segments):\n",
        "            start_idx = i * segment_size\n",
        "            end_idx = start_idx + segment_size if i < self.num_segments - 1 else len(data)\n",
        "\n",
        "            segment_data = data[start_idx:end_idx]\n",
        "            X = np.arange(len(segment_data)).reshape(-1, 1)\n",
        "            y = segment_data\n",
        "\n",
        "            model = LinearRegression().fit(X, y)\n",
        "            self.models.append(model)\n",
        "            self.segment_boundaries.append((start_idx, end_idx))\n",
        "\n",
        "    def query(self, key):\n",
        "        # Calculate segment size based on the segment boundaries\n",
        "        segment_size = self.segment_boundaries[0][1] - self.segment_boundaries[0][0]\n",
        "\n",
        "        # Determine the segment index based on the key\n",
        "        segment_idx = min(key // segment_size, self.num_segments - 1)\n",
        "        start_idx = self.segment_boundaries[segment_idx][0]\n",
        "\n",
        "        # Calculate the relative position within the segment\n",
        "        relative_pos = key - start_idx\n",
        "\n",
        "        # Return the prediction for that segment using the linear model\n",
        "        return self.models[segment_idx].predict([[relative_pos]])[0]\n",
        "\n",
        "    def query_range(self, start_key, end_key):\n",
        "      segment_size = self.segment_boundaries[0][1] - self.segment_boundaries[0][0]\n",
        "      start_segment_idx = min(start_key // segment_size, self.num_segments - 1)\n",
        "      end_segment_idx = min(end_key // segment_size, self.num_segments - 1)\n",
        "\n",
        "      results = []\n",
        "      for segment_idx in range(start_segment_idx, end_segment_idx + 1):\n",
        "          start_idx = self.segment_boundaries[segment_idx][0]\n",
        "          end_idx = self.segment_boundaries[segment_idx][1]\n",
        "\n",
        "          for i in range(start_idx, end_idx):\n",
        "              if start_key <= i <= end_key:\n",
        "                  results.append(i)\n",
        "      return results\n",
        "\n",
        "    def update_index(self, new_data):\n",
        "      combined_data = np.sort(np.concatenate([self.data, new_data]))\n",
        "      self.train(combined_data)"
      ],
      "metadata": {
        "id": "D5stNHuUi4Uu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridIndex:\n",
        "    def __init__(self, num_segments=10, hidden_layer_sizes=(50,), max_iter=1000, learning_rate_init=0.0005):\n",
        "        self.num_segments = num_segments\n",
        "        self.models = []\n",
        "        self.nn_model = MLPRegressor(\n",
        "            hidden_layer_sizes=hidden_layer_sizes,\n",
        "            max_iter=max_iter,\n",
        "            learning_rate_init=learning_rate_init,\n",
        "            solver='adam',\n",
        "            early_stopping=True,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    def train(self, data):\n",
        "        scaler = StandardScaler()\n",
        "        data_scaled = scaler.fit_transform(data.reshape(-1, 1))\n",
        "\n",
        "        X = np.arange(len(data)).reshape(-1, 1)\n",
        "        y = data\n",
        "        self.nn_model.fit(X, y)\n",
        "\n",
        "    def query(self, key):\n",
        "        return self.nn_model.predict([[key]])[0]\n",
        "\n",
        "    def query_range(self, start_key, end_key):\n",
        "        return [self.query(key) for key in range(start_key, end_key + 1)]\n",
        "\n",
        "    def update_index(self, new_data):\n",
        "        combined_data = np.sort(np.concatenate([self.data, new_data]))\n",
        "        self.train(combined_data)\n",
        "\n",
        "    def retrain_if_needed(self, data_update_count, threshold=100):\n",
        "        if data_update_count >= threshold:\n",
        "            self.train(self.data)\n",
        "            data_update_count = 0"
      ],
      "metadata": {
        "id": "3JXZeBJ8fMx-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(num_keys=1000):\n",
        "    return np.sort(np.random.randint(1, 100000, size=num_keys))\n",
        "\n",
        "# Measure Regular Query Performance\n",
        "def measure_regular_query_performance(index, data, num_queries=1000):\n",
        "    start_time = time.time()\n",
        "    queries = [random.choice(data) for _ in range(num_queries)]\n",
        "    results = [index.query(query) for query in queries]\n",
        "    query_time = time.time() - start_time\n",
        "    mse = mean_squared_error(queries, results)\n",
        "    return query_time, mse\n",
        "\n",
        "# Measure Range Query Performance\n",
        "def measure_range_query_performance(index, data, num_queries=1000):\n",
        "    start_time = time.time()\n",
        "    queries = [(random.choice(data), random.choice(data)) for _ in range(num_queries)]\n",
        "\n",
        "    sorted_data = np.sort(data)\n",
        "\n",
        "    results = []\n",
        "    for query in queries:\n",
        "        start_idx = bisect.bisect_left(sorted_data, query[0])\n",
        "        end_idx = bisect.bisect_right(sorted_data, query[1])\n",
        "        results.append(sorted_data[start_idx:end_idx])\n",
        "\n",
        "    query_time = time.time() - start_time\n",
        "\n",
        "    true_values = [list(filter(lambda x: query[0] <= x <= query[1], data)) for query in queries]\n",
        "\n",
        "    mse = mean_squared_error([len(true) for true in true_values], [len(result) for result in results])\n",
        "\n",
        "    return query_time, mse\n",
        "\n",
        "def compare_models(data):\n",
        "    piecewise_index = PiecewiseLinearIndex(num_segments=10)\n",
        "    hybrid_index = HybridIndex(num_segments=10)\n",
        "\n",
        "    start_time = time.time()\n",
        "    piecewise_index.train(data)\n",
        "    piecewise_training_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    hybrid_index.train(data)\n",
        "    hybrid_training_time = time.time() - start_time\n",
        "\n",
        "    piecewise_regular_query_time, piecewise_regular_mse = measure_regular_query_performance(piecewise_index, data)\n",
        "\n",
        "    hybrid_regular_query_time, hybrid_regular_mse = measure_regular_query_performance(hybrid_index, data)\n",
        "\n",
        "    piecewise_range_query_time, piecewise_range_mse = measure_range_query_performance(piecewise_index, data)\n",
        "\n",
        "    hybrid_range_query_time, hybrid_range_mse = measure_range_query_performance(hybrid_index, data)\n",
        "\n",
        "    print(f\"Piecewise Linear Index (BuzzDB-inspired):\")\n",
        "    print(f\"  Training Time: {piecewise_training_time:.4f} seconds\")\n",
        "    print(f\"  Regular Query Time (for {len(data)} queries): {piecewise_regular_query_time:.4f} seconds\")\n",
        "    print(f\"  Mean Squared Error for Regular Queries: {piecewise_regular_mse:.4f}\")\n",
        "    print(f\"  Range Query Time (for {len(data)} queries): {piecewise_range_query_time:.4f} seconds\")\n",
        "\n",
        "    print(f\"\\nHybrid Index (RMI + Neural Network):\")\n",
        "    print(f\"  Training Time: {hybrid_training_time:.4f} seconds\")\n",
        "    print(f\"  Regular Query Time (for {len(data)} queries): {hybrid_regular_query_time:.4f} seconds\")\n",
        "    print(f\"  Mean Squared Error for Regular Queries: {hybrid_regular_mse:.4f}\")\n",
        "    print(f\"  Range Query Time (for {len(data)} queries): {hybrid_range_query_time:.4f} seconds\")\n",
        "\n",
        "data = generate_data(num_keys=1000)\n",
        "\n",
        "compare_models(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7sjyCd_fYKm",
        "outputId": "280c6f38-f781-4d8a-8a0c-b5c8d1413d25"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Piecewise Linear Index (BuzzDB-inspired):\n",
            "  Training Time: 0.0085 seconds\n",
            "  Regular Query Time (for 1000 queries): 0.0898 seconds\n",
            "  Mean Squared Error for Regular Queries: 41762350513103.2500\n",
            "  Range Query Time (for 1000 queries): 0.0035 seconds\n",
            "\n",
            "Hybrid Index (RMI + Neural Network):\n",
            "  Training Time: 4.0782 seconds\n",
            "  Regular Query Time (for 1000 queries): 0.0876 seconds\n",
            "  Mean Squared Error for Regular Queries: 25947715440792.2227\n",
            "  Range Query Time (for 1000 queries): 0.0033 seconds\n"
          ]
        }
      ]
    }
  ]
}